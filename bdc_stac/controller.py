"""Data module."""

import warnings
from datetime import datetime as dt
from functools import lru_cache
from typing import Optional

import shapely.geometry
from bdc_catalog.models import Band, Collection, CompositeFunction, GridRefSys, Item, Tile, Timeline, ItemsProcessors
from flask import abort, current_app
from flask_sqlalchemy import Pagination, SQLAlchemy
from geoalchemy2.shape import to_shape
from sqlalchemy import Float, and_, cast, exc, func, or_

from .config import BDC_STAC_API_VERSION, BDC_STAC_BASE_URL, BDC_STAC_FILE_ROOT, BDC_STAC_MAX_LIMIT

with warnings.catch_warnings():
    warnings.simplefilter("ignore", category=exc.SAWarning)


db = SQLAlchemy()

session = db.create_scoped_session({"autocommit": True})

DATETIME_RFC339 = "%Y-%m-%dT%H:%M:%SZ"


def get_collection_items(
    collection_id=None,
    roles=None,
    item_id=None,
    bbox=None,
    datetime=None,
    ids=None,
    collections=None,
    intersects=None,
    page=1,
    limit=10,
    query=None,
    **kwargs,
) -> Pagination:
    """Retrieve a list of collection items based on filters.

    :param collection_id: Single Collection ID to include in the search for items.
                          Only Items in one of the provided Collection will be searched, defaults to None
    :type collection_id: str, optional
    :param item_id: item identifier, defaults to None
    :type item_id: str, optional
    :param bbox: bounding box for intersection [west, north, east, south], defaults to None
    :type bbox: list, optional
    :param datetime: Single date+time, or a range ('/' seperator), formatted to RFC 3339, section 5.6.
                     Use double dots '..' for open date ranges, defaults to None. If the start or end date of an image
                     generated by a temporal composition intersects the given datetime or range it will be included in the
                     result.
    :type datetime: str, optional
    :param ids: Array of Item ids to return. All other filter parameters that further restrict the
                number of search results are ignored, defaults to None
    :type ids: list, optional
    :param collections: Array of Collection IDs to include in the search for items.
                        Only Items in one of the provided Collections will be searched, defaults to None
    :type collections: list, optional
    :param intersects: Searches items by performing intersection between their geometry and provided GeoJSON geometry.
                       All GeoJSON geometry types must be supported., defaults to None
    :type intersects: dict, optional
    :param page: The page offset of results, defaults to 1
    :type page: int, optional
    :param limit: The maximum number of results to return (page size), defaults to 10
    :type limit: int, optional
    :param query: The STAC extra query internal properties
    :type query: dict, optional
    :return: list of collectio items
    :rtype: list
    """
    exclude = kwargs.get('exclude', [])

    columns = [
        func.concat(Collection.name, "-", Collection.version).label("collection"),
        Collection.collection_type,
        Collection.category,
        Item.metadata_.label("item_meta"),
        Item.name.label("item"),
        Item.id,
        Item.collection_id,
        Item.start_date.label("start"),
        Item.end_date.label("end"),
        Item.created,
        Item.updated,
        cast(Item.cloud_cover, Float).label("cloud_cover"),
        Item.footprint,
        Item.bbox,
        Tile.name.label("tile"),
    ]

    # For performance, only retrieve assets when required
    if 'assets' not in exclude:
        columns.append(Item.assets)

    if roles is None:
        roles = []

    where = [
        Collection.id == Item.collection_id,
        or_(Collection.is_public.is_(True),
            Collection.is_available.is_(True),
            Collection.id.in_([int(r.split(":")[0]) for r in roles])),
        Item.is_available.is_(True),
        Item.is_public.is_(True)
    ]

    if ids is not None:
        if isinstance(ids, str):
            ids = ids.split(",")
        where += [Item.name.in_(ids)]
    else:
        if collection_id is not None:
            where += [func.concat(Collection.name, "-", Collection.version) == collection_id]
        elif collections is not None:
            if isinstance(collections, str):
                collections = collections.split(",")
            where += [func.concat(Collection.name, "-", Collection.version).in_(collections)]

        if item_id is not None:
            where += [Item.name.like(item_id)]

        if query:
            filters = create_query_filter(query)
            where += filters

        if intersects is not None:
            where += [func.ST_Intersects(func.ST_GeomFromGeoJSON(str(intersects)), Item.bbox)]
        elif bbox is not None:
            try:
                if isinstance(bbox, str):
                    bbox = bbox.split(",")

                bbox = [float(x) for x in bbox]

                if bbox[0] == bbox[2] or bbox[1] == bbox[3]:
                    raise InvalidBoundingBoxError("")

                where += [
                    func.ST_Intersects(
                        func.ST_MakeEnvelope(
                            bbox[0],
                            bbox[1],
                            bbox[2],
                            bbox[3],
                            4326
                        ),
                        # TODO: Use footprint to intersect or bbox?
                        Item.bbox,
                    )
                ]
            except (ValueError, InvalidBoundingBoxError) as e:
                abort(400, f"'{bbox}' is not a valid bbox.")

        if datetime is not None:
            if "/" in datetime:
                matches_open = ("..", "")
                time_start, time_end = datetime.split("/")
                if time_start in matches_open:  # open start
                    date_filter = [or_(Item.start_date <= time_end, Item.end_date <= time_end)]
                elif time_end in matches_open:  # open end
                    date_filter = [or_(Item.start_date >= time_start, Item.end_date >= time_start)]
                else:  # closed range
                    date_filter = [
                        or_(
                            and_(Item.start_date >= time_start, Item.start_date <= time_end),
                            and_(Item.end_date >= time_start, Item.end_date <= time_end),
                            and_(Item.start_date < time_start, Item.end_date > time_end),
                        )
                    ]
            else:
                date_filter = [and_(Item.start_date <= datetime, Item.end_date >= datetime)]
            where += date_filter
    outer = [Item.tile_id == Tile.id]
    query = session.query(*columns).outerjoin(Tile, *outer).filter(*where).order_by(Item.start_date.desc(), Item.id)

    result = query.paginate(page=int(page), per_page=int(limit), error_out=False, max_per_page=BDC_STAC_MAX_LIMIT)

    return result


@lru_cache()
def get_collection_eo(collection_id):
    """Get Collection Eletro-Optical properties.

    Args:
        collection_id (str): collection identifier
    Returns:
        eo_gsd, eo_bands (tuple(float, dict)):
    """
    bands = Band.query().filter(Band.collection_id == collection_id)
    eo_bands = list()
    eo_gsd = 0.0

    for band in bands:
        band_meta = dict(
            name=band.name,
            common_name=band.common_name,
            description=band.description,
            min=float(band.min_value) if band.min_value is not None else None,
            max=float(band.max_value) if band.max_value is not None else None,
            nodata=float(band.nodata) if band.nodata is not None else None,
            scale=float(band.scale_mult) if band.scale_mult is not None else None,
            scale_add=float(band.scale_add) if band.scale_add is not None else None,
            data_type=band.data_type,
        )
        band_meta.update(band.properties)
        resolutions = band.eo_resolutions
        if resolutions is None:
            current_app.logger.warning(f'No resolution configured for {band.collection.name} - Band {band.name}')
            continue

        eo_bands.append(band_meta)
        if resolutions[0] > eo_gsd:
            eo_gsd = resolutions[0]

    return {"eo:gsd": eo_gsd, "eo:bands": eo_bands}


def get_collection_bands(collection_id):
    """Retrive a dict of bands for a given collection.

    :param collection_id: collection identifier
    :type collection_id: str
    :return: dict of bands for the collection
    :rtype: dict
    """
    bands = (
        session.query(
            Band.name,
            Band.common_name,
            cast(Band.min, Float).label("min"),
            cast(Band.max, Float).label("max"),
            cast(Band.nodata, Float).label("nodata"),
            cast(Band.scale, Float).label("scale"),
            Band.data_type,
        )
        .filter(Band.collection_id == collection_id)
        .all()
    )
    bands_json = dict()

    for b in bands:
        bands_json[b.common_name] = {
            k: v for k, v in b._asdict().items() if k != "common_name" and not k.startswith("_")
        }

    return bands_json


def get_collection_tiles(collection_id):
    """Retrieve a list of tiles for a given collection.

    :param collection_id: collection identifier
    :type collection_id: str
    :return: list of tiles for the collection
    :rtype: list
    """
    tiles = (
        session.query(Tile.name)
        .filter(Item.collection_id == collection_id, Item.tile_id == Tile.id)
        .group_by(Tile.name)
        .all()
    )

    return [t.name for t in tiles]


@lru_cache()
def get_collection_crs(collection_id):
    """Retrive the CRS for a given collection.

    :param collection_id: collection identifier
    :type collection_id: str
    :return: CRS for the collection
    :rtype: str
    """
    grs = (
        session.query(GridRefSys)
        .filter(Collection.id == collection_id, Collection.grid_ref_sys_id == GridRefSys.id)
        .first()
    )

    return grs.crs


def get_collection_timeline(collection_id):
    """Retrive a list of dates for a given collection.

    :param collection_id: collection identifier
    :type collection_id: str
    :return: list of dates for the collection
    :rtype: list
    """
    timeline = (
        session.query(Timeline.time_inst)
        .filter(Timeline.collection_id == collection_id)
        .order_by(Timeline.time_inst.asc())
        .all()
    )

    return [dt.fromisoformat(str(t.time_inst)).strftime("%Y-%m-%d") for t in timeline]


def get_collection_quicklook(collection_id):
    """Retrive a list of bands used to create the quicklooks for a given collection.

    :param collection_id: collection identifier
    :type collection_id: str
    :return: list of bands
    :rtype: list.
    """
    quicklook_bands = session.execute(
        "SELECT  array[r.name, g.name, b.name] as quicklooks "
        "FROM bdc.quicklook q "
        "INNER JOIN bdc.bands r ON q.red = r.id "
        "INNER JOIN bdc.bands g ON q.green = g.id "
        "INNER JOIN bdc.bands b ON q.blue = b.id "
        "INNER JOIN bdc.collections c ON q.collection_id = c.id "
        "WHERE c.id = :collection_id",
        {"collection_id": collection_id},
    ).fetchone()

    return quicklook_bands["quicklooks"] if quicklook_bands else None


def get_collections(collection_id=None, roles=None, assets_kwargs=None):
    """Retrieve information of all collections or one if an id is given.

    :param collection_id: collection identifier
    :type collection_id: str
    :return: list of collections
    :rtype: list
    """
    columns = [
        Collection,
        CompositeFunction.name.label("composite_function"),
        GridRefSys.name.label("grid_ref_sys"),
    ]

    if roles is None:
        roles = []

    where = [
        Collection.is_available.is_(True),
        or_(Collection.is_public.is_(True), Collection.id.in_([int(r.split(":")[0]) for r in roles])),
    ]

    if collection_id:
        where.append(func.concat(Collection.name, "-", Collection.version) == collection_id)

    result = (
        session.query(*columns)
        .outerjoin(CompositeFunction, Collection.composite_function_id == CompositeFunction.id)
        .outerjoin(GridRefSys, Collection.grid_ref_sys_id == GridRefSys.id)
        .filter(*where)
        .all()
    )

    collections = list()
    default_stac_extensions = ["bdc", "version", "processing", "item-assets"]

    for r in result:
        category = r.Collection.category

        providers = [
            provider.to_dict()
            for provider in r.Collection.providers
        ]

        collection_extensions = []
        if r.Collection.collection_type == 'datacube':
            collection_extensions.append('datacube')

        if category == 'sar' or category == 'eo':
            collection_extensions.append(category)

        tiles = get_collection_tiles(r.Collection.id)

        collection = {
            "id": f'{r.Collection.name}-{r.Collection.version}',
            "stac_version": BDC_STAC_API_VERSION,
            "stac_extensions": default_stac_extensions + collection_extensions,
            "title": r.Collection.title,
            "version": r.Collection.version,
            "deprecated": False,
            "description": r.Collection.description,
            "keywords": r.Collection.keywords,
            "providers": providers,
            "summaries": r.Collection.summaries,
            "item_assets": r.Collection.item_assets,
            "properties": r.Collection.properties or {},
            "bdc:type": r.Collection.collection_type,
        }

        if r.Collection.grs:
            collection["bdc:grs"] = r.Collection.grs.name
        if r.Collection.composite_function:
            collection["bdc:composite_function"] = r.composite_function
        if tiles:
            collection["bdc:tiles"] = tiles

        if r.Collection.metadata_ and ("rightsList" in r.Collection.metadata_) and (len(r.Collection.metadata_["rightsList"]) > 0):
            collection["license"] = r.Collection.metadata_["rightsList"][0].get("rights", "")
        else:
            collection["license"] = ""

        bbox = to_shape(r.Collection.spatial_extent).bounds if r.Collection.spatial_extent else None

        start, end = None, None

        if r.Collection.start_date:
            start = r.Collection.start_date.strftime(DATETIME_RFC339)
            if r.Collection.end_date:
                end = r.Collection.end_date.strftime(DATETIME_RFC339)

        collection["extent"] = {
            "spatial": {"bbox": [bbox]},
            "temporal": {"interval": [[start, end]]},
        }

        quicklooks = get_collection_quicklook(r.Collection.id)

        if quicklooks is not None:
            collection["bdc:bands_quicklook"] = quicklooks

        if category == 'eo':
            collection_eo = get_collection_eo(r.Collection.id)
            collection["properties"].update(collection_eo)

        if r.Collection.metadata_:
            if "platform" in r.Collection.metadata_:
                collection["properties"]["instruments"] = r.Collection.metadata_["platform"]["instruments"]
                collection["properties"]["platform"] = r.Collection.metadata_["platform"]["code"]

                r.Collection.metadata_.pop("platform")  # platform info is displayed on properties
            collection["bdc:metadata"] = r.Collection.metadata_

        if r.Collection.collection_type == "cube":
            proj4text = get_collection_crs(r.Collection.id)

            datacube = {
                "x": dict(type="spatial", axis="x", extent=[bbox[0], bbox[2]], reference_system=proj4text),
                "y": dict(type="spatial", axis="y", extent=[bbox[1], bbox[3]], reference_system=proj4text),
                "temporal": dict(type="temporal", extent=[start, end], values=get_collection_timeline(r.Collection.id)),
            }
            if category == 'eo':
                datacube["bands"] = dict(type="bands", values=[band["name"] for band in collection_eo["eo:bands"]])

            collection["cube:dimensions"] = datacube
            collection["bdc:crs"] = get_collection_crs(r.Collection.id)
            collection["bdc:temporal_composition"] = r.Collection.temporal_composition_schema

        collection["links"] = [
            {
                "href": f"{BDC_STAC_BASE_URL}/collections/{r.Collection.identifier}{assets_kwargs}",
                "rel": "self",
                "type": "application/json",
                "title": "Link to this document",
            },
            {
                "href": f"{BDC_STAC_BASE_URL}/collections/{r.Collection.identifier}/items{assets_kwargs}",
                "rel": "items",
                "type": "application/json",
                "title": f"Items of the collection {r.Collection.identifier}",
            },
            {
                "href": f"{BDC_STAC_BASE_URL}/collections{assets_kwargs}",
                "rel": "parent",
                "type": "application/json",
                "title": "Link to catalog collections",
            },
            {
                "href": f"{BDC_STAC_BASE_URL}/{assets_kwargs}",
                "rel": "root",
                "type": "application/json",
                "title": "API landing page (root catalog)",
            },
        ]

        collections.append(collection)

    return collections


def get_catalog(roles=None):
    """Retrieve all available collections.

    :return: a list of available collections
    :rtype: list
    """
    if not roles:
        roles = []

    collections = (
        session.query(
            Collection.id,
            func.concat(Collection.name, "-", Collection.version).label("name"),
            Collection.title,
        )
        .filter(
            or_(
                Collection.is_public.is_(True),
                Collection.id.in_([int(r.split(":")[0]) for r in roles]),
            )
        )
        .all()
    )
    return collections


def make_geojson(items, assets_kwargs="", exclude=None):
    """Generate a list of STAC Items from a list of collection items.

    param items: collection items to be formated as GeoJSON Features
    type items: list
    param extension: The STAC extension for Item Context (sar/eo/label).
    type extension: str
    return: GeoJSON Features.
    rtype: list
    """
    features = list()
    exclude = exclude or []

    for i in items:
        geom = i.footprint or i.bbox
        geom = shapely.geometry.mapping(to_shape(geom))
        feature = {
            "type": "Feature",
            "id": i.item,
            "collection": i.collection,
            "stac_version": BDC_STAC_API_VERSION,
            "stac_extensions": ["bdc", "checksum", i.category],
            "geometry": geom,
            "links": [
                {
                    "href": f"{BDC_STAC_BASE_URL}/collections/{i.collection}/items/{i.item}{assets_kwargs}",
                    "rel": "self",
                },
                {"href": f"{BDC_STAC_BASE_URL}/collections/{i.collection}{assets_kwargs}", "rel": "parent"},
                {"href": f"{BDC_STAC_BASE_URL}/collections/{i.collection}{assets_kwargs}", "rel": "collection"},
                {"href": f"{BDC_STAC_BASE_URL}/", "rel": "root"},
            ],
        }

        # Processors
        processors = get_item_processors(i.id)

        bbox = list()
        if i.bbox:
            bbox = to_shape(i.bbox).bounds
        feature["bbox"] = bbox

        properties = {
            "datetime": i.start.strftime(DATETIME_RFC339),
            "start_datetime": i.start.strftime(DATETIME_RFC339),
            "end_datetime": i.end.strftime(DATETIME_RFC339),
            "created": i.created.strftime(DATETIME_RFC339),
            "updated": i.updated.strftime(DATETIME_RFC339)
        }
        properties.update(i.item_meta or {})
        properties.update(processors)

        bands = {}
        if i.tile:
            properties["bdc:tiles"] = [i.tile]

        if i.category == 'eo':
            properties["eo:cloud_cover"] = i.cloud_cover
            bands = get_collection_eo(i.collection_id)

        if hasattr(i, 'assets'):
            for key, value in i.assets.items():
                value["href"] = BDC_STAC_FILE_ROOT + value["href"] + assets_kwargs

                if i.category == 'eo':
                    for band in bands["eo:bands"]:
                        if band["name"] == key:
                            value["eo:bands"] = [band]
            feature["assets"] = i.assets

        feature["properties"] = properties

        for key in exclude:
            feature.pop(key, None)

        features.append(feature)
    return features


def get_item_processors(item_id: int) -> dict:
    """List the Processors used to compose the given Item.

    Note:
         Follows the STAC Extension `processing <https://github.com/stac-extensions/processing>`_.
    """
    processors = ItemsProcessors.get_processors(item_id)
    proc_root = None
    processors_obj = {}
    for proc in processors:
        if proc_root is None or (proc_root is not None and proc.level > proc_root.level):
            proc_root = proc
        processors_obj[proc.facility] = proc.version

    out = {}
    if processors_obj:
        out["processing:lineage"] = proc_root.name
        out["processing:facility"] = proc_root.facility
        out["processing:level"] = proc_root.level
        out["processing:software"] = processors_obj

    return out


def create_query_filter(query):
    """Create STAC query filter for SQLAlchemy.

    Notes:
        Queryable properties must be mapped in these functions.
    """
    mapping = {
        "eq": "__eq__",
        "neq": "__ne__",
        "lt": "__lt__",
        "lte": "__le__",
        "gt": "__gt__",
        "gte": "__ge__",
        "startsWith": "startswith",
        "endsWith": "endswith",
        "contains": "contains",
        "in": "in_",
    }

    bdc_properties = {
        "bdc:tile": Tile.name,
        "eo:cloud_cover": Item.cloud_cover,
    }

    filters = []

    for column, _filters in query.items():
        for op, value in _filters.items():
            if bdc_properties.get(column):
                f = getattr(bdc_properties[column], mapping[op])(value)
            # TODO: Remove the hard-code for comparison on JSON fields (Only text comparisons)
            else:
                f = getattr(Item.metadata_[column].astext, mapping[op])(value)
            filters.append(f)

    return filters


def parse_fields_parameter(fields: Optional[str] = None):
    """Parses the string parameter `fields` to include/exclude certain fields in response.

    Follow the `STAC API Fields Fragment <https://github.com/radiantearth/stac-api-spec/blob/v1.0.0-rc.1/fragments/fields/README.md>`.
    """
    if fields is None:
        return [], []

    include = []
    exclude = []
    fields = fields.split(',')

    for field in fields:
        if field.startswith('-'):
            splitter = field.split('.')
            left = splitter[0][1:]
            exclude.append((left, splitter[1:]) if len(splitter) > 1 else left)
        else:
            include.append(field)

    return include, exclude


class InvalidBoundingBoxError(Exception):
    """Exception for malformed bounding box."""

    def __init__(self, description):
        """Initialize exception with a description.

        :param description: exception description.
        :type description: str
        """
        super(InvalidBoundingBoxError, self).__init__()
        self.description = description

    def __str__(self):
        """:return: str representation of the exception."""
        return str(self.description)
